{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb23396e-9baa-4d7c-8631-f13fa48a1139",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from pyspark.sql import SparkSession, DataFrameWriter\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ee75748-7a9f-464b-bd2e-9896cff363fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://5a34cbc5025c:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>extract-transform</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7efdc3a30190>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создание спарк сессии\n",
    "spark = SparkSession.builder.master(\"local\").enableHiveSupport().appName(\"extract-transform\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42e7d4a7-4286-4214-b6bc-12f0bfd17650",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Читаем данные из паркета\n",
    "df = spark.read.format(\"parquet\").load('data_in/competition_data_final_pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "725ce023-a74d-4068-ba77-ae3d84710542",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- region_name: string (nullable = true)\n",
      " |-- city_name: string (nullable = true)\n",
      " |-- cpe_manufacturer_name: string (nullable = true)\n",
      " |-- cpe_model_name: string (nullable = true)\n",
      " |-- url_host: string (nullable = true)\n",
      " |-- cpe_type_cd: string (nullable = true)\n",
      " |-- cpe_model_os_type: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- part_of_day: string (nullable = true)\n",
      " |-- request_cnt: long (nullable = true)\n",
      " |-- user_id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97ca2c0d-45f0-4b44-810e-8bcb6fc1442d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Создаем локальное представление датафрейма, как sql таблицы mts\n",
    "df.createOrReplaceTempView(\"mts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f42b0c32-a5b4-436c-9470-a5fa4fb68b85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+\n",
      "|price|cpe_model_name|\n",
      "+-----+--------------+\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "| null|     Mi 8 Lite|\n",
      "+-----+--------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select price, cpe_model_name from mts where cpe_model_name = 'Mi 8 Lite'\").show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8dd77b-8464-4a5d-a7c2-89a472d9f24c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a71170-cc89-4360-ab91-5295d4eb93ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f678ac8-28c9-4e64-822b-7ba8974ab96d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = spark.sql(\"select user_id, max(price) as price from mts group by user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe13575a-0ecb-4624-9169-b9ba0e7390cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "415317"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21496c5b-47a3-419e-a9c7-03840f4a5467",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sub_1 = spark.sql(\"select user_id, round(avg(request_cnt), 3) as avg_request_cnt, count(request_cnt)as count_request_cnt \"\n",
    "    \" from mts group by user_id\")\n",
    "data_learn = data.select(\"user_id\", \"price\").join(df_sub_1, \"user_id\", 'left')\n",
    "df_sub_2 = spark.sql(\"select user_id, round(avg(request_cnt), 3) as avg_night_request_cnt, count(request_cnt)as count_night_request_cnt \"\n",
    "    \" from mts where part_of_day = 'night' group by user_id\")\n",
    "data_learn = data_learn.join(df_sub_2, \"user_id\", 'left')\n",
    "df_sub_3 = spark.sql(\"select user_id, round(avg(request_cnt), 3) as avg_day_request_cnt, count(request_cnt)as count_day_request_cnt \"\n",
    "    \" from mts where part_of_day = 'day' group by user_id\")\n",
    "data_learn = data_learn.join(df_sub_3, \"user_id\", 'left')\n",
    "df_sub_4 = spark.sql(\"select user_id, round(avg(request_cnt), 3) as avg_morning_request_cnt, count(request_cnt)as count_morning_request_cnt \"\n",
    "    \" from mts where part_of_day = 'morning' group by user_id\")\n",
    "data_learn = data_learn.join(df_sub_4, \"user_id\", 'left')\n",
    "df_sub_5 = spark.sql(\"select user_id, round(avg(request_cnt), 3) as avg_evening_request_cnt, count(request_cnt)as count_evening_request_cnt \"\n",
    "    \" from mts where part_of_day = 'evening' group by user_id\")\n",
    "data_learn = data_learn.join(df_sub_5, \"user_id\", 'left')\n",
    "\n",
    "df_sub_6 = spark.sql(\"select user_id, \"\n",
    "    \" round(avg(sum_date_request_cnt), 3) as avg_sum_date_request_cnt\"\n",
    "    \" from (select user_id, date, sum(request_cnt) as sum_date_request_cnt from mts group by user_id, date) as t1\"\n",
    "    \" group by user_id\")\n",
    "data_learn = data_learn.join(df_sub_6, \"user_id\", 'left')\n",
    "df_sub_7 = spark.sql(\"select user_id, \"\n",
    "    \" round(avg(sum_date_request_cnt), 3) as day_avg_sum_date_request_cnt\"\n",
    "    \" from (select user_id, date, sum(request_cnt) as sum_date_request_cnt from mts where part_of_day = 'day' group by user_id, date) as t2\"\n",
    "    \" group by user_id\")\n",
    "data_learn = data_learn.join(df_sub_7, \"user_id\", 'left')\n",
    "df_sub_8 = spark.sql(\"select user_id, \"\n",
    "    \" round(avg(sum_date_request_cnt), 3) as night_avg_sum_date_request_cnt\"\n",
    "    \" from (select user_id, date, sum(request_cnt) as sum_date_request_cnt from mts where part_of_day = 'night' group by user_id, date) as t3\"\n",
    "    \" group by user_id\")\n",
    "data_learn = data_learn.join(df_sub_8, \"user_id\", 'left')\n",
    "df_sub_9 = spark.sql(\"select user_id, \"\n",
    "    \" round(avg(sum_date_request_cnt), 3) as morning_avg_sum_date_request_cnt\"\n",
    "    \" from (select user_id, date, sum(request_cnt) as sum_date_request_cnt from mts where part_of_day = 'morning' group by user_id, date) as t4\"\n",
    "    \" group by user_id\")\n",
    "data_learn = data_learn.join(df_sub_9, \"user_id\", 'left')\n",
    "df_sub_10 = spark.sql(\"select user_id, \"\n",
    "    \" round(avg(sum_date_request_cnt), 3) as evening_avg_sum_date_request_cnt\"\n",
    "    \" from (select user_id, date, sum(request_cnt) as sum_date_request_cnt from mts where part_of_day = 'evening' group by user_id, date) as t5\"\n",
    "    \" group by user_id\")\n",
    "data_learn = data_learn.join(df_sub_10, \"user_id\", 'left')\n",
    "\n",
    "df_sub_11 = spark.sql(\"select user_id, count(date) as count_date\"\n",
    "    \" from (select user_id, date from mts group by user_id, date) as t6 group by user_id\")\n",
    "data_learn = data_learn.join(df_sub_11, \"user_id\", 'left')\n",
    "df_sub_12 = spark.sql(\"select user_id, count(date) as count_day_date\"\n",
    "    \" from (select user_id, date from mts where part_of_day = 'day' group by user_id, date) as t7 group by user_id\")\n",
    "data_learn = data_learn.join(df_sub_12, \"user_id\", 'left')\n",
    "df_sub_13 = spark.sql(\"select user_id, count(date) as count_night_date\"\n",
    "    \" from (select user_id, date from mts where part_of_day = 'night' group by user_id, date) as t8 group by user_id\")\n",
    "data_learn = data_learn.join(df_sub_13, \"user_id\", 'left')\n",
    "df_sub_14 = spark.sql(\"select user_id, count(date) as count_morning_date\"\n",
    "    \" from (select user_id, date from mts where part_of_day = 'morning' group by user_id, date) as t9 group by user_id\")\n",
    "data_learn = data_learn.join(df_sub_14, \"user_id\", 'left')\n",
    "df_sub_15 = spark.sql(\"select user_id, count(date) as count_evening_date\"\n",
    "    \" from (select user_id, date from mts where part_of_day = 'evening' group by user_id, date) as t10 group by user_id\")\n",
    "data_learn = data_learn.join(df_sub_15, \"user_id\", 'left')\n",
    "\n",
    "df_sub_16 = spark.sql(\"select user_id, avg(count_part_of_day_date) as avg_count_part_of_day_date\"\n",
    "    \" from (select user_id, date, count(part_of_day) as count_part_of_day_date\"\n",
    "    \" from (select user_id, date, part_of_day from mts group by user_id, date, part_of_day) as t11\"\n",
    "    \" group by user_id, date) as t12 group by user_id\")\n",
    "data_learn = data_learn.join(df_sub_16, \"user_id\", 'left')\n",
    "\n",
    "df_sub_17 = spark.sql(\"select user_id, avg(lag_date) as avg_lag_date, max(lag_date) as max_lag_date, min(lag_date) as min_lag_date\"\n",
    "    \" from (select user_id, int(date - lag(date) over (partition by user_id order by date)) as lag_date\"\n",
    "    \" from (select user_id, date from mts group by user_id, date order by user_id, date) as t13) as t14\"\n",
    "    \" group by user_id order by user_id\")\n",
    "data_learn = data_learn.join(df_sub_17, \"user_id\", 'left')\n",
    "\n",
    "df_sub_18 = spark.sql(\"select user_id, count(region_name) as count_region_name\"\n",
    "    \" from (select user_id, region_name from mts group by user_id, region_name) as t15\"\n",
    "    \" group by user_id order by user_id\")\n",
    "data_learn = data_learn.join(df_sub_18, \"user_id\", 'left')\n",
    "df_sub_19 = spark.sql(\"select user_id, count(city_name) as count_city_name\"\n",
    "    \" from (select user_id, city_name from mts group by user_id, city_name) as t16\"\n",
    "    \" group by user_id order by user_id\")\n",
    "data_learn = data_learn.join(df_sub_19, \"user_id\", 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1cda35d-a78e-4190-87bb-945787a0eb66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 146 ms, sys: 76.9 ms, total: 223 ms\n",
      "Wall time: 18min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_learn.write.parquet(path=\"data_out/data_transform_last\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b90cace8-2299-4e99-9352-8f9e21ac9ffd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Чтобы не формировать data_learn сразу формируя запросы прочитаем уже имеющийся, а затем прибавим новые фичи\n",
    "data_last = spark.read.format(\"parquet\").load('data_out/data_transform_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18110676-3906-4a1a-86af-57e5515f7447",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.7 ms, sys: 6.26 ms, total: 25 ms\n",
      "Wall time: 438 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_sub_20 = spark.sql(\"select user_id, url_host as top_1_url_sum_request_cnt\"\n",
    "          \" from (select user_id, url_host, ROW_NUMBER() over (partition by user_id order by sum_request_cnt desc) as rank_sum_request_cnt \"\n",
    "          \" from (select user_id, url_host, sum(request_cnt) as sum_request_cnt\"\n",
    "          \" from mts group by user_id, url_host) as t1) as t2\"\n",
    "          \" where rank_sum_request_cnt = 1\")\n",
    "data_learn = data_last.join(df_sub_20, \"user_id\", 'left')\n",
    "df_sub_21 = spark.sql(\"select user_id, url_host as top_2_url_sum_request_cnt\"\n",
    "          \" from (select user_id, url_host, ROW_NUMBER() over (partition by user_id order by sum_request_cnt desc) as rank_sum_request_cnt \"\n",
    "          \" from (select user_id, url_host, sum(request_cnt) as sum_request_cnt\"\n",
    "          \" from mts group by user_id, url_host) as t1) as t2\"\n",
    "          \" where rank_sum_request_cnt = 2\")\n",
    "data_learn = data_learn.join(df_sub_21, \"user_id\", 'left')\n",
    "df_sub_22 = spark.sql(\"select user_id, url_host as top_3_url_sum_request_cnt\"\n",
    "          \" from (select user_id, url_host, ROW_NUMBER() over (partition by user_id order by sum_request_cnt desc) as rank_sum_request_cnt \"\n",
    "          \" from (select user_id, url_host, sum(request_cnt) as sum_request_cnt\"\n",
    "          \" from mts group by user_id, url_host) as t1) as t2\"\n",
    "          \" where rank_sum_request_cnt = 3\")\n",
    "data_learn = data_learn.join(df_sub_22, \"user_id\", 'left')\n",
    "df_sub_23 = spark.sql(\"select user_id, url_host as top_4_url_sum_request_cnt\"\n",
    "          \" from (select user_id, url_host, ROW_NUMBER() over (partition by user_id order by sum_request_cnt desc) as rank_sum_request_cnt \"\n",
    "          \" from (select user_id, url_host, sum(request_cnt) as sum_request_cnt\"\n",
    "          \" from mts group by user_id, url_host) as t1) as t2\"\n",
    "          \" where rank_sum_request_cnt = 4\")\n",
    "data_learn = data_learn.join(df_sub_23, \"user_id\", 'left')\n",
    "df_sub_24 = spark.sql(\"select user_id, url_host as top_5_url_sum_request_cnt\"\n",
    "          \" from (select user_id, url_host, ROW_NUMBER() over (partition by user_id order by sum_request_cnt desc) as rank_sum_request_cnt \"\n",
    "          \" from (select user_id, url_host, sum(request_cnt) as sum_request_cnt\"\n",
    "          \" from mts group by user_id, url_host) as t1) as t2\"\n",
    "          \" where rank_sum_request_cnt = 5\")\n",
    "data_learn = data_learn.join(df_sub_24, \"user_id\", 'left')\n",
    "df_sub_25 = spark.sql(\"select user_id, url_host as top_1_url_count_request_cnt\"\n",
    "          \" from (select user_id, url_host, ROW_NUMBER() over (partition by user_id order by count_url_host desc) as rank_count_url_host \"\n",
    "          \" from (select user_id, url_host, count(url_host) as count_url_host\"\n",
    "          \" from mts group by user_id, url_host) as t1) as t2\"\n",
    "          \" where rank_count_url_host = 1\")\n",
    "data_learn = data_learn.join(df_sub_25, \"user_id\", 'left')\n",
    "df_sub_26 = spark.sql(\"select user_id, url_host as top_2_url_count_request_cnt\"\n",
    "          \" from (select user_id, url_host, ROW_NUMBER() over (partition by user_id order by count_url_host desc) as rank_count_url_host \"\n",
    "          \" from (select user_id, url_host, count(url_host) as count_url_host\"\n",
    "          \" from mts group by user_id, url_host) as t1) as t2\"\n",
    "          \" where rank_count_url_host = 2\")\n",
    "data_learn = data_learn.join(df_sub_26, \"user_id\", 'left')\n",
    "df_sub_27 = spark.sql(\"select user_id, url_host as top_3_url_count_request_cnt\"\n",
    "          \" from (select user_id, url_host, ROW_NUMBER() over (partition by user_id order by count_url_host desc) as rank_count_url_host \"\n",
    "          \" from (select user_id, url_host, count(url_host) as count_url_host\"\n",
    "          \" from mts group by user_id, url_host) as t1) as t2\"\n",
    "          \" where rank_count_url_host = 3\")\n",
    "data_learn = data_learn.join(df_sub_27, \"user_id\", 'left')\n",
    "df_sub_28 = spark.sql(\"select user_id, region_name as region_name\"\n",
    "          \" from (select user_id, region_name, ROW_NUMBER() over (partition by user_id order by count_url_host desc) as rank_count_url_host \"\n",
    "          \" from (select user_id, region_name, count(url_host) as count_url_host\"\n",
    "          \" from mts group by user_id, region_name) as t1) as t2\"\n",
    "          \" where rank_count_url_host = 1\")\n",
    "data_learn = data_learn.join(df_sub_28, \"user_id\", 'left')\n",
    "df_sub_29 = spark.sql(\"select user_id, cpe_model_name from mts group by user_id, cpe_model_name\")\n",
    "data_learn = data_learn.join(df_sub_29, \"user_id\", 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cbb9d58-bd53-448b-9ba0-b9592fa7541b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 109 ms, sys: 49.3 ms, total: 158 ms\n",
      "Wall time: 12min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_learn.write.parquet(path=\"data_out/data_transform_last_1\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fa24507-0321-442d-b8b6-bb4159ce99fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_test = spark.read.format(\"parquet\").load('data_out/data_transform_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76cecac1-cb71-4fb1-983c-5167c719142c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "415317"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b85d34-734d-49f8-a32a-bee6946a6558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e045b7-7158-4372-abcd-5b587a3aaa9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "037929b3-5fa7-4373-b851-d72b1402a836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------------------+\n",
      "|user_id|         region_name|rank_count_url_host|\n",
      "+-------+--------------------+-------------------+\n",
      "|      0|              Москва|                  1|\n",
      "|      1|              Москва|                  1|\n",
      "|      1|     Санкт-Петербург|                  2|\n",
      "|      1|  Московская область|                  3|\n",
      "|      2|     Республика Коми|                  1|\n",
      "|      3| Воронежская область|                  1|\n",
      "|      4|  Краснодарский край|                  1|\n",
      "|      4|Республика Башкор...|                  2|\n",
      "|      4|Волгоградская обл...|                  3|\n",
      "|      4|   Самарская область|                  4|\n",
      "|      4| Саратовская область|                  5|\n",
      "|      5|Ленинградская обл...|                  1|\n",
      "|      5|     Санкт-Петербург|                  2|\n",
      "|      6|  Московская область|                  1|\n",
      "|      7|              Москва|                  1|\n",
      "|      7|  Московская область|                  2|\n",
      "|      8|Нижегородская обл...|                  1|\n",
      "|      9|Нижегородская обл...|                  1|\n",
      "|     10|Нижегородская обл...|                  1|\n",
      "|     11|     Приморский край|                  1|\n",
      "|     12|Республика Башкор...|                  1|\n",
      "|     13|Свердловская область|                  1|\n",
      "|     14|Удмуртская Респуб...|                  1|\n",
      "|     15|Удмуртская Респуб...|                  1|\n",
      "|     16| Челябинская область|                  1|\n",
      "|     17| Вологодская область|                  1|\n",
      "|     18|  Краснодарский край|                  1|\n",
      "|     19|   Красноярский край|                  1|\n",
      "|     20|              Москва|                  1|\n",
      "|     20|  Московская область|                  2|\n",
      "+-------+--------------------+-------------------+\n",
      "only showing top 30 rows\n",
      "\n",
      "CPU times: user 14.2 ms, sys: 9.61 ms, total: 23.8 ms\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_sub_28 = spark.sql(\"select user_id, region_name, ROW_NUMBER() over (partition by user_id order by count_url_host desc) as rank_count_url_host \"\n",
    "          \" from (select user_id, region_name, count(url_host) as count_url_host\"\n",
    "          \" from mts group by user_id, region_name) as t1\")\n",
    "df_sub_28.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcf18704-f5a6-4426-97ac-645cc3403345",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415317\n",
      "+-------+--------------------+\n",
      "|user_id|      cpe_model_name|\n",
      "+-------+--------------------+\n",
      "| 222203|   iPhone 12 Pro Max|\n",
      "|  83980|       Honor 7S Dual|\n",
      "| 106223|       iPhone 6 Plus|\n",
      "| 250496|Galaxy A71 Dual R...|\n",
      "|  33908|           iPhone XR|\n",
      "| 323731|       iPhone 7 Plus|\n",
      "| 131179|           iPhone 11|\n",
      "| 106000|           iPhone SE|\n",
      "|  94313| Galaxy J7 2017 Dual|\n",
      "| 179669|  Galaxy J3 LTE Dual|\n",
      "|  84503|            Redmi 4X|\n",
      "| 303462|      Galaxy A32 LTE|\n",
      "|   2732|            iPhone 7|\n",
      "| 208843|            iPhone 7|\n",
      "| 307944|     Galaxy A10 Dual|\n",
      "| 355218|       iPhone 12 Pro|\n",
      "| 336597| Galaxy J4 2018 Dual|\n",
      "| 281195|     Galaxy A40 Dual|\n",
      "| 120897|           iPhone XR|\n",
      "| 267029|             Redmi 8|\n",
      "| 343268|     Galaxy A50 Dual|\n",
      "| 409254|             Y7 2019|\n",
      "|  56820|        Redmi 5 Plus|\n",
      "| 401639|        Redmi 5 Plus|\n",
      "| 212281|            Redmi 9C|\n",
      "| 143308|           iPhone 11|\n",
      "| 303765|             Y9 2018|\n",
      "| 271161|                MI 6|\n",
      "|  46647|           iPhone 11|\n",
      "| 140299|   iPhone 12 Pro Max|\n",
      "+-------+--------------------+\n",
      "only showing top 30 rows\n",
      "\n",
      "CPU times: user 21.4 ms, sys: 7.72 ms, total: 29.1 ms\n",
      "Wall time: 1min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_sub_28 = spark.sql(\"select user_id, cpe_model_name from mts group by user_id, cpe_model_name\")\n",
    "print(df_sub_28.count())\n",
    "df_sub_28.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9770e6d-78c1-4c26-8e00-a8fe9e170c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415317\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564f6f5c-1525-4042-a812-a785db49f613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbe25ce0-1d46-4a7f-a6e6-c1cb6c0f7df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "415317"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a650c81-af71-4cc7-8ad2-31cbeea37a41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16915f2e-21f5-41b5-b4be-c7d70c5c0f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# googleads.g.doubl... 38 mail.yandex.ru  144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec51ec49-3ca4-44e2-83ab-09747bd0076a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+-------------------+\n",
      "|user_id|            url_host|rank_sum_request_cnt|rank_count_url_host|\n",
      "+-------+--------------------+--------------------+-------------------+\n",
      "|      0|googleads.g.doubl...|                   1|                  1|\n",
      "|      0|node1.online.sber...|                   3|                  2|\n",
      "|      0|  online.sberbank.ru|                   5|                  3|\n",
      "|      0|        yastatic.net|                   2|                  4|\n",
      "|      0|avatars.mds.yande...|                   4|                  5|\n",
      "|      0|              vk.com|                   6|                  6|\n",
      "|      0|tpc.googlesyndica...|                   7|                  7|\n",
      "|      0|           yandex.ru|                   9|                  8|\n",
      "|      0|         s0.2mdn.net|                  11|                  9|\n",
      "|      0|          ad.mail.ru|                  12|                 10|\n",
      "|      0|        ads.adfox.ru|                  13|                 11|\n",
      "|      0|          google.com|                  15|                 12|\n",
      "|      0|      ssp.rambler.ru|                   8|                 13|\n",
      "|      0|              eda.ru|                  10|                 14|\n",
      "|      0|         i.ytimg.com|                  14|                 15|\n",
      "|      0|               hh.ru|                  16|                 16|\n",
      "|      0|          m.avito.ru|                  17|                 17|\n",
      "|      0|      wildberries.ru|                  18|                 18|\n",
      "|      0|            hhcdn.ru|                  19|                 19|\n",
      "|      0|              wer.ru|                  20|                 20|\n",
      "|      0|ads.betweendigita...|                  22|                 21|\n",
      "|      0|    banners.adfox.ru|                  25|                 22|\n",
      "|      0|       ssp.otm-r.com|                  26|                 23|\n",
      "|      0|            relap.io|                  28|                 24|\n",
      "|      0|             m.ok.ru|                  29|                 25|\n",
      "|      0|   tube.buzzoola.com|                  21|                 26|\n",
      "|      0|code.directadvert.ru|                  23|                 27|\n",
      "|      0|     play.google.com|                  24|                 28|\n",
      "|      0|       gorodrabot.ru|                  27|                 29|\n",
      "|      0|moskva.gorodrabot.ru|                  30|                 30|\n",
      "+-------+--------------------+--------------------+-------------------+\n",
      "only showing top 30 rows\n",
      "\n",
      "CPU times: user 38.5 ms, sys: 19.4 ms, total: 57.9 ms\n",
      "Wall time: 4min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "spark.sql(\"select user_id, url_host, ROW_NUMBER() over (partition by user_id order by sum_request_cnt desc) as rank_sum_request_cnt, \"\n",
    "          \" ROW_NUMBER() over (partition by user_id order by count_url_host desc) as rank_count_url_host\"\n",
    "          \" from (select user_id, url_host, sum(request_cnt) as sum_request_cnt, count(url_host) as count_url_host\"\n",
    "          \" from mts group by user_id, url_host) as t1\").orderBy(\"user_id\").show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6d9a91-86b0-4497-8b1e-ddeb06add889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341a618f-c59a-46c9-a120-c17dad81472e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7daa176-8d5c-4c82-b61b-313e73d45f0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------\n",
      " user_id           | 99002  \n",
      " age               | 41.0   \n",
      " is_male           | 0      \n",
      " max_request_cnt   | 8      \n",
      " avg_request_cnt   | 1.34   \n",
      " count_request_cnt | 639    \n",
      "-RECORD 1-------------------\n",
      " user_id           | 155506 \n",
      " age               | 33.0   \n",
      " is_male           | 0      \n",
      " max_request_cnt   | 5      \n",
      " avg_request_cnt   | 1.727  \n",
      " count_request_cnt | 22     \n",
      "-RECORD 2-------------------\n",
      " user_id           | 188276 \n",
      " age               | 35.0   \n",
      " is_male           | 1      \n",
      " max_request_cnt   | 4      \n",
      " avg_request_cnt   | 1.414  \n",
      " count_request_cnt | 111    \n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data_learn = spark.sql(\"with sub_1 as\"\n",
    "#     \" (select user_id, max(request_cnt) as max_request_cnt, round(avg(request_cnt), 3) as avg_request_cnt, count(request_cnt)as count_request_cnt \"\n",
    "#     \" from mts group by user_id)\"\n",
    "#     \", sub_2 as (select user_id, max(request_cnt) as max_night_request_cnt, \"\n",
    "#     \" round(avg(request_cnt), 3) as avg_night_request_cnt, count(request_cnt)as count_night_request_cnt \"\n",
    "#     \" from mts where part_of_day = 'night' group by user_id)\"\n",
    "    # \", sub_3 as (select user_id, max(request_cnt) as max_day_request_cnt, \"\n",
    "    # \" round(avg(request_cnt), 3) as avg_day_request_cnt, count(request_cnt)as count_day_request_cnt \"\n",
    "    # \" from mts where part_of_day = 'day' group by user_id)\"\n",
    "    # \", sub_4 as (select user_id, max(request_cnt) as max_morning_request_cnt, \"\n",
    "    # \" round(avg(request_cnt), 3) as avg_morning_request_cnt, count(request_cnt)as count_morning_request_cnt \"\n",
    "    # \" from mts where part_of_day = 'morning' group by user_id)\"\n",
    "    # \", sub_5 as (select user_id, max(request_cnt) as max_evening_request_cnt, \"\n",
    "    # \" round(avg(request_cnt), 3) as avg_evening_request_cnt, count(request_cnt)as count_evening_request_cnt \"\n",
    "    # \" from mts where part_of_day = 'evening' group by user_id)\"\n",
    "    # \", sub_6 as (select user_id, max(sum_date_request_cnt) as max_sum_date_request_cnt, min(sum_date_request_cnt) as min_sum_date_request_cnt, \"\n",
    "    # \" round(avg(sum_date_request_cnt), 3) as avg_sum_date_request_cnt\"\n",
    "    # \" from (select user_id, date, sum(request_cnt) as sum_date_request_cnt from mts group by user_id, date) as t1\"\n",
    "    # \" group by user_id)\"\n",
    "    # \", sub_7 as (select user_id, max(sum_date_request_cnt) as max_sum_date_day_request_cnt, min(sum_date_request_cnt) as min_sum_date_day_request_cnt, \"\n",
    "    # \" round(avg(sum_date_request_cnt), 3) as avg_sum_date_day_request_cnt\"\n",
    "    # \" from (select user_id, date, sum(request_cnt) as sum_date_request_cnt from mts where part_of_day = 'day' group by user_id, date) as t2\"\n",
    "    # \" group by user_id)\"\n",
    "    # \", sub_8 as (select user_id, max(sum_date_request_cnt) as max_sum_date_night_request_cnt, min(sum_date_request_cnt) as min_sum_date_night_request_cnt, \"\n",
    "    # \"round(avg(sum_date_request_cnt), 3) as avg_sum_date_night_request_cnt\"\n",
    "    # \" from (select user_id, date, sum(request_cnt) as sum_date_request_cnt from mts where part_of_day = 'night' group by user_id, date) as t3\"\n",
    "    # \" group by user_id)\"\n",
    "    # \", sub_9 as (select user_id, max(sum_date_request_cnt) as max_sum_date_morning_request_cnt, min(sum_date_request_cnt) as min_sum_date_morning_request_cnt, \"\n",
    "    # \" round(avg(sum_date_request_cnt), 3) as avg_sum_date_morning_request_cnt\"\n",
    "    # \" from (select user_id, date, sum(request_cnt) as sum_date_request_cnt from mts where part_of_day = 'morning' group by user_id, date) as t4\"\n",
    "    # \" group by user_id)\"\n",
    "    # \", sub_10 as (select user_id, max(sum_date_request_cnt) as max_sum_date_evening_request_cnt, min(sum_date_request_cnt) as min_sum_date_evening_request_cnt, \"\n",
    "    # \" round(avg(sum_date_request_cnt), 3) as avg_sum_date_evening_request_cnt\"\n",
    "    # \" from (select user_id, date, sum(request_cnt) as sum_date_request_cnt from mts where part_of_day = 'evening' group by user_id, date) as t5\"\n",
    "    # \" group by user_id)\"\n",
    "    # \", sub_11 as (select user_id, count(date) as count_date\"\n",
    "    # \" from (select user_id, date from mts group by user_id, date) as t6 group by user_id)\"\n",
    "    # \", sub_12 as (select user_id, count(date) as count_day_date\"\n",
    "    # \" from (select user_id, date from mts where part_of_day = 'day' group by user_id, date) as t7 group by user_id)\"\n",
    "    # \", sub_13 as (select user_id, count(date) as count_night_date\"\n",
    "    # \" from (select user_id, date from mts where part_of_day = 'night' group by user_id, date) as t8 group by user_id)\"\n",
    "    # \", sub_14 as (select user_id, count(date) as count_morning_date\"\n",
    "    # \" from (select user_id, date from mts where part_of_day = 'morning' group by user_id, date) as t9 group by user_id)\"\n",
    "    # \", sub_15 as (select user_id, count(date) as count_evening_date\"\n",
    "    # \" from (select user_id, date from mts where part_of_day = 'evening' group by user_id, date) as t10 group by user_id)\"\n",
    "    # \", sub_16 as (select user_id, avg(count_part_of_day_date) as avg_count_part_of_day_date,\"\n",
    "    # \" max(count_part_of_day_date) as max_count_part_of_day_date, min(count_part_of_day_date) as min_count_part_of_day_date\"\n",
    "    # \" from (select user_id, date, count(part_of_day) as count_part_of_day_date\"\n",
    "    # \" from (select user_id, date, part_of_day from mts group by user_id, date, part_of_day) as t11\"\n",
    "    # \" group by user_id, date) as t12 group by user_id)\"\n",
    "    # \", sub_17 as (select user_id, avg(lag_date) as avg_lag_date, max(lag_date) as max_lag_date, min(lag_date) as min_lag_date\"\n",
    "    # \" from (select user_id, int(date - lag(date) over (partition by user_id order by date)) as lag_date\"\n",
    "    # \" from (select user_id, date from mts group by user_id, date order by user_id, date) as t13) as t14\"\n",
    "    # \" group by user_id order by user_id)\"\n",
    "    # \", sub_18 as (select user_id, count(region_name) as count_region_name\"\n",
    "    # \" from (select user_id, region_name from mts group by user_id, region_name) as t15\"\n",
    "    # \" group by user_id order by user_id)\"\n",
    "    # \", sub_19 as (select user_id, count(city_name) as count_city_name\"\n",
    "    # \" from (select user_id, city_name from mts group by user_id, city_name) as t16\"\n",
    "    # \" group by user_id order by user_id)\"                     \n",
    "    # ).show(3, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc80bbb7-29d0-4fe6-bb13-5a20ef6994b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------\n",
      " user_id           | 0     \n",
      " age               | 35.0  \n",
      " is_male           | 0     \n",
      " max_request_cnt   | 5     \n",
      " avg_request_cnt   | 1.473 \n",
      " count_request_cnt | 131   \n",
      "-RECORD 1------------------\n",
      " user_id           | 1     \n",
      " age               | 41.0  \n",
      " is_male           | 0     \n",
      " max_request_cnt   | 6     \n",
      " avg_request_cnt   | 1.496 \n",
      " count_request_cnt | 700   \n",
      "-RECORD 2------------------\n",
      " user_id           | 2     \n",
      " age               | 25.0  \n",
      " is_male           | 0     \n",
      " max_request_cnt   | 4     \n",
      " avg_request_cnt   | 1.154 \n",
      " count_request_cnt | 356   \n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_test.show(3, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa0efaf-6648-4a62-bab4-4116ac73f436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
